#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
åˆ†ç±»ç›‘æ§å™¨ - æŒç»­ç›‘æ§å¹¶åˆ†ç±»æ–°ä¸‹è½½çš„PDFæ–‡ä»¶
"""

import sys
import time
import logging
from pathlib import Path
from watchdog.observers import Observer
from watchdog.events import FileSystemEventHandler
import json
from concurrent.futures import ProcessPoolExecutor, ThreadPoolExecutor, as_completed
from threading import Lock

from pdf_classifier import PDFClassifier, ProcessedFilesDB


class PDFWatcher(FileSystemEventHandler):
    """PDFæ–‡ä»¶ç›‘æ§å™¨"""
    
    def __init__(self, classifier, logger, stable_seconds=15, workers=4):
        self.classifier = classifier
        self.logger = logger
        self.stable_seconds = stable_seconds
        self.workers = workers
        self.pending_files = {}  # {path: first_seen_time}
        self.processing_files = set()  # æ­£åœ¨å¤„ç†çš„æ–‡ä»¶
        self.lock = Lock()  # çº¿ç¨‹é”
        self.executor = ThreadPoolExecutor(max_workers=workers)
        self.futures = []  # è·Ÿè¸ªè¿›è¡Œä¸­çš„ä»»åŠ¡
        self.logger.info(f"âš¡ ä½¿ç”¨çº¿ç¨‹æ±  ({workers} çº¿ç¨‹)")
        self.logger.info(f"ğŸ’¡ PDFè§£æå—GILé™åˆ¶ï¼Œå®é™…åŠ é€Ÿçº¦ 2-3x")
    
    def _classify_single_file(self, path):
        """å¤„ç†å•ä¸ªæ–‡ä»¶ï¼ˆçº¿ç¨‹å®‰å…¨ï¼‰"""
        try:
            pdf_path = Path(path)
            if pdf_path.exists():
                with self.lock:
                    self.processing_files.add(path)
                
                self.logger.info(f"ğŸ—‚ï¸  åˆ†ç±»: {pdf_path.name}")
                self.classifier.process_file(pdf_path)
                
                with self.lock:
                    self.processing_files.discard(path)
            else:
                self.logger.warning(f"âš ï¸  æ–‡ä»¶ä¸å­˜åœ¨: {pdf_path.name}")
        except Exception as e:
            self.logger.error(f"âŒ åˆ†ç±»å¤±è´¥ {Path(path).name}: {e}")
            with self.lock:
                self.processing_files.discard(path)
    
    def on_created(self, event):
        """æ–‡ä»¶åˆ›å»ºäº‹ä»¶"""
        if event.is_directory:
            return
        
        if event.src_path.lower().endswith('.pdf'):
            with self.lock:
                # é¿å…é‡å¤æ·»åŠ 
                if event.src_path not in self.pending_files and event.src_path not in self.processing_files:
                    self.logger.info(f"ğŸ“¥ å‘ç°æ–°æ–‡ä»¶: {Path(event.src_path).name}")
                    self.pending_files[event.src_path] = time.time()
    
    def process_pending(self):
        """å¤„ç†å¾…å¤„ç†æ–‡ä»¶ï¼ˆå¹¶è¡Œï¼‰"""
        current_time = time.time()
        to_process = []
        
        with self.lock:
            for path, first_seen in list(self.pending_files.items()):
                if current_time - first_seen >= self.stable_seconds:
                    to_process.append(path)
                    del self.pending_files[path]
        
        if to_process:
            # ä½¿ç”¨çº¿ç¨‹æ± å¹¶è¡Œå¤„ç†
            for path in to_process:
                future = self.executor.submit(self._classify_single_file, path)
                self.futures.append(future)
            
            # æ¸…ç†å·²å®Œæˆçš„ä»»åŠ¡
            self.futures = [f for f in self.futures if not f.done()]
    
    def shutdown(self):
        """å…³é—­çº¿ç¨‹æ± """
        self.logger.info("â³ ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ...")
        self.executor.shutdown(wait=True)
        self.logger.info("âœ… æ‰€æœ‰ä»»åŠ¡å·²å®Œæˆ")


def main():
    """ä¸»å‡½æ•°"""
    # åŠ è½½é…ç½®
    config_path = Path("integrated_config.json")
    with open(config_path, 'r', encoding='utf-8') as f:
        config = json.load(f)
    
    # è®¾ç½®æ—¥å¿—
    logging.basicConfig(
        level=logging.INFO,
        format="%(asctime)s [%(levelname)s] %(message)s",
        datefmt="%Y-%m-%d %H:%M:%S",
        handlers=[
            logging.StreamHandler(sys.stdout),
            logging.FileHandler("classify_watcher.log", encoding="utf-8")
        ]
    )
    logger = logging.getLogger("classify_watcher")
    
    # è·¯å¾„é…ç½®
    watch_dir = Path(config["paths"]["download_dir"]).resolve()
    target_dir = Path(config["paths"]["classified_dir"]).resolve()
    
    logger.info("=" * 60)
    logger.info("ğŸš€ å¯åŠ¨åˆ†ç±»ç›‘æ§å™¨")
    logger.info("=" * 60)
    logger.info(f"ç›‘æ§ç›®å½•: {watch_dir}")
    logger.info(f"åˆ†ç±»ç›®å½•: {target_dir}")
    logger.info(f"ğŸ“ é…ç½®æ–‡ä»¶è¯»å–: download_dir={config['paths']['download_dir']}, classified_dir={config['paths']['classified_dir']}")
    
    # æ£€æŸ¥å¾…åˆ†ç±»æ–‡ä»¶
    existing_pdfs = list(watch_dir.rglob("*.pdf"))
    # ä¿®æ”¹ï¼šå¤„ç†æ‰€æœ‰PDFæ–‡ä»¶ï¼Œä¸é™äºç‰¹å®šå‚å•†å­ç›®å½•
    if existing_pdfs:
        logger.info(f"ğŸ” å‘ç° {len(existing_pdfs)} ä¸ªå¾…åˆ†ç±»PDFæ–‡ä»¶")
        for pdf in existing_pdfs[:5]:
            relative_path = pdf.relative_to(watch_dir)
            logger.info(f"   - {relative_path}")
        if len(existing_pdfs) > 5:
            logger.info(f"   ... è¿˜æœ‰ {len(existing_pdfs) - 5} ä¸ªæ–‡ä»¶")
    else:
        logger.info("ğŸ“­ å½“å‰æ²¡æœ‰å¾…åˆ†ç±»æ–‡ä»¶")
    logger.info("")
    
    # åˆ›å»ºåˆ†ç±»å™¨
    db_path = Path("classified_files.db")
    classifier_db = ProcessedFilesDB(db_path)
    metadata_file = target_dir / "metadata.jsonl"
    logger.info(f"ğŸ“Š æ•°æ®åº“: {db_path.absolute()}")
    
    classifier = PDFClassifier(
        source_dir=watch_dir,
        target_dir=target_dir,
        db=classifier_db,
        metadata_file=metadata_file,
        head_pages=config.get("classifier", {}).get("head_pages", 3),
        mode="copy",
        dry_run=False
    )
    
    logger.info(f"ğŸ¯ åˆ†ç±»å™¨é…ç½®: source={classifier.source_dir}, target={classifier.target_dir}")
    
    # è·å–å¹¶å‘æ•°
    workers = config.get("classifier", {}).get("workers", 4)
    logger.info(f"âš¡ å¹¶å‘çº¿ç¨‹æ•°: {workers}")
    
    # åˆ›å»ºç›‘æ§å™¨
    event_handler = PDFWatcher(
        classifier, 
        logger,
        stable_seconds=config.get("classifier", {}).get("min_stable_seconds", 15),
        workers=workers
    )
    observer = Observer()
    observer.schedule(event_handler, str(watch_dir), recursive=True)
    observer.start()
    
    logger.info("âœ… ç›‘æ§å·²å¯åŠ¨ï¼Œç­‰å¾…æ–°æ–‡ä»¶...")
    logger.info("æŒ‰ Ctrl+C åœæ­¢\n")
    
    # å¤„ç†å¯åŠ¨æ—¶å­˜åœ¨çš„æ–‡ä»¶ï¼ˆå¹¶è¡Œï¼‰
    if existing_pdfs:
        logger.info(f"ğŸ”„ å¤„ç†å¯åŠ¨å‰å·²å­˜åœ¨çš„ {len(existing_pdfs)} ä¸ªæ–‡ä»¶ ({workers} å¹¶å‘)...")
        with ThreadPoolExecutor(max_workers=workers) as executor:
            futures = [executor.submit(event_handler._classify_single_file, str(pdf)) for pdf in existing_pdfs]
            for future in as_completed(futures):
                pass  # ç»“æœå·²åœ¨ _classify_single_file ä¸­è®°å½•
        logger.info(f"âœ… å¯åŠ¨æ—¶æ–‡ä»¶å¤„ç†å®Œæˆ\n")
    
    try:
        while True:
            time.sleep(5)
            event_handler.process_pending()
    except KeyboardInterrupt:
        logger.info("\nâš ï¸  ç”¨æˆ·ä¸­æ–­")
        observer.stop()
        event_handler.shutdown()
    
    observer.join()
    logger.info("âœ… ç›‘æ§å·²åœæ­¢")


if __name__ == "__main__":
    main()
