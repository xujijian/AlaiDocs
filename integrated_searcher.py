#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æŒç»­æœç´¢ä¸‹è½½ç³»ç»Ÿ - å®Œæ•´é›†æˆç‰ˆ
æ•´åˆ ChatGPT å…³é”®è¯ç”Ÿæˆ + DuckDuckGo æœç´¢ + å®é™…ä¸‹è½½åŠŸèƒ½

ä½œè€…: AI åŠ©æ‰‹
ç‰ˆæœ¬: 1.1.0
æ—¥æœŸ: 2026-01-26
Python: 3.10+
"""

import argparse
import atexit
import json
import logging
import signal
import subprocess
import sys
import time
from collections import defaultdict
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Optional, Set

from chatgpt_keyword_generator import GeminiKeywordGenerator
from keyword_manager import KeywordManager


class IntegratedSearcher:
    """é›†æˆä¸‹è½½åŠŸèƒ½çš„æŒç»­æœç´¢å™¨"""
    
    def __init__(
        self,
        output_dir: Path,
        keyword_db_path: Path,
        use_browser: bool = True,
        config: Optional[Dict] = None,
        logger: Optional[logging.Logger] = None
    ):
        """
        åˆå§‹åŒ–æœç´¢å™¨
        
        Args:
            output_dir: è¾“å‡ºç›®å½•
            keyword_db_path: å…³é”®è¯æ•°æ®åº“è·¯å¾„
            use_browser: æ˜¯å¦ä½¿ç”¨æµè§ˆå™¨ç‰ˆæœ¬ï¼ˆå¼ºåˆ¶ä¸º Trueï¼Œå¿…é¡»ä½¿ç”¨ Chrome ä»¥é¿å…è¢«æ‹’ç»ï¼‰
            config: é…ç½®å­—å…¸
            logger: æ—¥å¿—è®°å½•å™¨
        """
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
        self.logger = logger or logging.getLogger(__name__)
        
        # å¤„ç†é…ç½®ï¼šå¦‚æœæ˜¯åµŒå¥—é…ç½®åˆ™æ‰å¹³åŒ–ï¼Œå¦åˆ™ä½¿ç”¨é»˜è®¤
        if config:
            # æ£€æŸ¥æ˜¯å¦æ˜¯åµŒå¥—é…ç½®
            if any(k in config for k in ["gemini", "chatgpt", "keywords", "search", "loop_control", "limits"]):
                base_config = self._default_config()
                flattened = self._flatten_config(config)
                base_config.update(flattened)
                self.config = base_config
            else:
                # å·²ç»æ˜¯æ‰å¹³é…ç½®
                base_config = self._default_config()
                base_config.update(config)
                self.config = base_config
        else:
            self.config = self._default_config()
        
        # å¼ºåˆ¶ä½¿ç”¨æµè§ˆå™¨ç‰ˆæœ¬ï¼ˆå¿…é¡»ä½¿ç”¨ Chrome ä»¥é¿å…è¯·æ±‚è¢«æ‹’ç»ï¼‰
        self.use_browser = True
        
        # åˆå§‹åŒ–ç»„ä»¶
        self.keyword_manager = KeywordManager(keyword_db_path, self.logger)
        self.chatgpt_generator = None
        
        # è¿è¡ŒçŠ¶æ€
        self.is_running = False
        self.current_round = 0
        self.total_files_downloaded = 0
        self.total_size_downloaded = 0
        
        # çŠ¶æ€æ–‡ä»¶
        self.state_file = self.output_dir / "search_state.json"
        self._load_state()
        
        # æ³¨å†Œä¼˜é›…é€€å‡ºå¤„ç†
        self._setup_signal_handlers()
    
    def _default_config(self) -> Dict:
        """é»˜è®¤é…ç½®"""
        return {
            "gemini_headless": False,
            "gemini_response_timeout": 60,
            "keywords_per_round": 10,
            "focus_areas": [
                "DC-DC converter",
                "buck converter",
                "boost converter",
                "automotive power",
            ],
            "results_per_keyword": 20,
            "max_downloads_per_keyword": 10,
            "max_rounds": 0,
            "min_files_per_round": 3,
            "round_interval": 300,
            "total_size_limit_gb": 50,
            "total_files_limit": 5000,
            "save_state_interval": 5,
        }
    
    def _flatten_config(self, config: Dict) -> Dict:
        """å°†åµŒå¥—é…ç½®æ‰å¹³åŒ–"""
        flattened = {}
        
        # å¤„ç† gemini é…ç½®
        if "gemini" in config:
            gemini_cfg = config["gemini"]
            flattened["gemini_headless"] = gemini_cfg.get("headless", False)
            flattened["gemini_response_timeout"] = gemini_cfg.get("response_timeout", 60)
        # å…¼å®¹æ—§çš„ chatgpt é…ç½®
        elif "chatgpt" in config:
            chatgpt_cfg = config["chatgpt"]
            flattened["gemini_headless"] = chatgpt_cfg.get("headless", False)
        
        # å¤„ç† keywords é…ç½®
        if "keywords" in config:
            keywords_cfg = config["keywords"]
            flattened["keywords_per_round"] = keywords_cfg.get("per_round", 10)
            flattened["focus_areas"] = keywords_cfg.get("focus_areas", [])
        
        # å¤„ç† search é…ç½®
        if "search" in config:
            search_cfg = config["search"]
            flattened["results_per_keyword"] = search_cfg.get("results_per_keyword", 20)
            flattened["max_downloads_per_keyword"] = search_cfg.get("max_downloads_per_keyword", 10)
        
        # å¤„ç† loop_control é…ç½®
        if "loop_control" in config:
            loop_cfg = config["loop_control"]
            flattened["max_rounds"] = loop_cfg.get("max_rounds", 0)
            flattened["min_files_per_round"] = loop_cfg.get("min_files_per_round", 3)
            flattened["round_interval"] = loop_cfg.get("round_interval_seconds", 300)
        
        # å¤„ç† limits é…ç½®
        if "limits" in config:
            limits_cfg = config["limits"]
            flattened["total_size_limit_gb"] = limits_cfg.get("total_size_gb", 50)
            flattened["total_files_limit"] = limits_cfg.get("total_files", 5000)
        
        # å¤„ç† other é…ç½®
        if "other" in config:
            other_cfg = config["other"]
            flattened["save_state_interval"] = other_cfg.get("save_state_interval", 5)
        
        return flattened
    
    def _load_state(self):
        """åŠ è½½è¿è¡ŒçŠ¶æ€"""
        if self.state_file.exists():
            try:
                with open(self.state_file, 'r', encoding='utf-8') as f:
                    state = json.load(f)
                    self.current_round = state.get("current_round", 0)
                    self.logger.info(f"ğŸ“¥ åŠ è½½çŠ¶æ€: ç¬¬ {self.current_round} è½®")
            except Exception as e:
                self.logger.error(f"âŒ åŠ è½½çŠ¶æ€å¤±è´¥: {e}")
        
        # å§‹ç»ˆåŸºäºå®é™…æ–‡ä»¶ç³»ç»Ÿé‡æ–°ç»Ÿè®¡ï¼ˆé¿å…ç´¯è®¡è¯¯å·®ï¼‰
        actual_stats = self._count_downloaded_files()
        self.total_files_downloaded = actual_stats["files_downloaded"]
        self.total_size_downloaded = actual_stats["total_size"]
        if self.total_files_downloaded > 0:
            self.logger.info(f"ğŸ“Š å½“å‰å®é™…æ–‡ä»¶: {self.total_files_downloaded} ä¸ª, {self.total_size_downloaded / (1024**3):.2f} GB")
    
    def _save_state(self):
        """ä¿å­˜è¿è¡ŒçŠ¶æ€"""
        try:
            state = {
                "current_round": self.current_round,
                "total_files_downloaded": self.total_files_downloaded,
                "total_size_downloaded": self.total_size_downloaded,
                "last_updated": datetime.now().isoformat()
            }
            with open(self.state_file, 'w', encoding='utf-8') as f:
                json.dump(state, f, indent=2)
        except Exception as e:
            self.logger.error(f"âŒ ä¿å­˜çŠ¶æ€å¤±è´¥: {e}")
    
    def _setup_signal_handlers(self):
        """è®¾ç½®ä¿¡å·å¤„ç†å™¨ï¼ˆä¼˜é›…é€€å‡ºï¼‰"""
        def signal_handler(signum, frame):
            self.logger.warning(f"\nâš ï¸ æ”¶åˆ°ä¸­æ–­ä¿¡å· ({signum})ï¼Œæ­£åœ¨ä¼˜é›…é€€å‡º...")
            self.is_running = False
            self._cleanup()
            sys.exit(0)
        
        # æ³¨å†Œä¿¡å·å¤„ç†
        signal.signal(signal.SIGINT, signal_handler)  # Ctrl+C
        signal.signal(signal.SIGTERM, signal_handler)  # ç»ˆæ­¢ä¿¡å·
        
        # æ³¨å†Œé€€å‡ºå¤„ç†
        atexit.register(self._cleanup)
    
    def _cleanup(self):
        """æ¸…ç†èµ„æº"""
        try:
            if hasattr(self, 'chatgpt_generator') and self.chatgpt_generator:
                self.logger.info("ğŸ§¹ å…³é—­æµè§ˆå™¨...")
                self._cleanup_components()
            
            if hasattr(self, 'state_file'):
                self._save_state()
                self.logger.info("ğŸ’¾ çŠ¶æ€å·²ä¿å­˜")
        except Exception as e:
            self.logger.error(f"æ¸…ç†èµ„æºæ—¶å‡ºé”™: {e}")
            self.logger.error(f"æ¸…ç†èµ„æºæ—¶å‡ºé”™: {e}")
    
    def _initialize_components(self):
        """åˆå§‹åŒ–ç»„ä»¶"""
        self.logger.info("ğŸ”§ åˆå§‹åŒ– Gemini å…³é”®è¯ç”Ÿæˆå™¨...")
        
        try:
            self.chatgpt_generator = GeminiKeywordGenerator(
                logger=self.logger,
                headless=self.config["gemini_headless"],
                response_timeout=self.config.get("gemini_response_timeout", 60)
            )
            self.chatgpt_generator.start()
            
            if not self.chatgpt_generator.check_login_status():
                self.logger.error("âŒ ChatGPT æœªç™»å½•")
                return False
            
            self.logger.info("âœ… ç»„ä»¶åˆå§‹åŒ–å®Œæˆ")
            return True
        except KeyboardInterrupt:
            self.logger.warning("âš ï¸ åˆå§‹åŒ–è¢«ç”¨æˆ·ä¸­æ–­")
            raise
        except Exception as e:
            self.logger.error(f"âŒ åˆå§‹åŒ–å¤±è´¥: {e}")
            return False
    
    def _cleanup_components(self):
        """æ¸…ç†ç»„ä»¶"""
        if self.chatgpt_generator:
            self.chatgpt_generator.stop()
    
    def _generate_keywords(self) -> List[str]:
        """ç”Ÿæˆæ–°å…³é”®è¯"""
        self.logger.info(f"\n{'='*60}")
        self.logger.info(f"ğŸ¯ ç¬¬ {self.current_round + 1} è½®: ç”Ÿæˆå…³é”®è¯")
        self.logger.info(f"{'='*60}\n")
        
        context = self._prepare_context()
        keywords = self.chatgpt_generator.generate_keywords(
            context=context,
            num_keywords=self.config["keywords_per_round"],
            focus_areas=self.config["focus_areas"]
        )
        
        if not keywords:
            return []
        
        new_keywords = self.keyword_manager.filter_new_keywords(keywords)
        self.logger.info(f"âœ… ç”Ÿæˆ {len(keywords)} ä¸ªå…³é”®è¯ï¼Œ{len(new_keywords)} ä¸ªæ–°çš„")
        
        return new_keywords
    
    def _prepare_context(self) -> Dict:
        """å‡†å¤‡ä¸Šä¸‹æ–‡"""
        recent_keywords = self.keyword_manager.get_recent_keywords(limit=10)
        vendors_found = self._analyze_downloaded_vendors()
        
        return {
            "downloaded_count": self.total_files_downloaded,
            "vendors": list(vendors_found),
            "used_keywords": recent_keywords,
            "current_round": self.current_round,
        }
    
    def _analyze_downloaded_vendors(self) -> Set[str]:
        """åˆ†æå·²ä¸‹è½½ä¾›åº”å•†"""
        vendors = set()
        for vendor_dir in self.output_dir.iterdir():
            if vendor_dir.is_dir() and not vendor_dir.name.startswith(('_', '.')):
                vendors.add(vendor_dir.name)
        return vendors
    
    def _search_and_download(self, keywords: List[str]) -> Dict:
        """æœç´¢å¹¶ä¸‹è½½"""
        self.logger.info(f"\n{'='*60}")
        self.logger.info(f"ğŸ” ç¬¬ {self.current_round + 1} è½®: æœç´¢ä¸ä¸‹è½½")
        self.logger.info(f"{'='*60}\n")
        
        round_stats = {
            "files_downloaded": 0,
            "total_size": 0,
            "keyword_results": {}
        }
        
        for i, keyword in enumerate(keywords, 1):
            self.logger.info(f"\n--- å…³é”®è¯ {i}/{len(keywords)}: {keyword} ---")
            
            try:
                result = self._download_with_ddg_fetcher(keyword)
                
                files_found = result["files_downloaded"]
                size = result["total_size"]
                
                round_stats["files_downloaded"] += files_found
                round_stats["total_size"] += size
                round_stats["keyword_results"][keyword] = result
                
                self.keyword_manager.add_keyword(keyword, files_found, size)
                self.logger.info(f"âœ… {keyword}: {files_found} æ–‡ä»¶, {size / (1024*1024):.2f} MB")
                
            except Exception as e:
                self.logger.error(f"âŒ å¤„ç†å¤±è´¥: {e}")
                self.keyword_manager.add_keyword(keyword, 0, 0)
            
            if self._check_limits():
                break
        
        return round_stats
    
    def _download_with_ddg_fetcher(self, keyword: str) -> Dict:
        """ä½¿ç”¨ ddg_fetcher ä¸‹è½½ï¼ˆå¼ºåˆ¶ä½¿ç”¨ Chrome æµè§ˆå™¨ç‰ˆæœ¬ï¼‰"""
        # å¼ºåˆ¶ä½¿ç”¨æµè§ˆå™¨ç‰ˆæœ¬ï¼ˆChromeï¼‰ä»¥é¿å…è¯·æ±‚è¢«æ‹’ç»
        script = "ddg_fetcher_browser.py"
        
        cmd = [
            sys.executable,
            script,
            "--query", keyword,
            "--out", str(self.output_dir),
            "--max-results", str(self.config["results_per_keyword"]),
        ]
        
        # å¦‚æœé…ç½®äº†æ— å¤´æ¨¡å¼
        if self.config.get("gemini_headless", False):
            cmd.append("--headless")
        
        self.logger.info(f"ğŸŒ å¯åŠ¨ Chrome æµè§ˆå™¨æœç´¢: {keyword}")
        self.logger.debug(f"æ‰§è¡Œå‘½ä»¤: {' '.join(cmd)}")
        
        # æ‰§è¡Œå‘½ä»¤ï¼ˆä¸æ•è·è¾“å‡ºï¼Œç›´æ¥æ˜¾ç¤ºåœ¨æ§åˆ¶å°ï¼‰
        try:
            result = subprocess.run(
                cmd,
                timeout=600,  # 10åˆ†é’Ÿè¶…æ—¶
                text=True
            )
            
            # æ£€æŸ¥è¿”å›ç 
            if result.returncode != 0:
                self.logger.error(f"âŒ Chrome æµè§ˆå™¨è„šæœ¬æ‰§è¡Œå¤±è´¥ï¼Œè¿”å›ç : {result.returncode}")
                return {"files_downloaded": 0, "total_size": 0}
            
            # ç»Ÿè®¡ä¸‹è½½æ–‡ä»¶
            return self._count_downloaded_files()
            
        except subprocess.TimeoutExpired:
            self.logger.error(f"â° Chrome æµè§ˆå™¨æ‰§è¡Œè¶…æ—¶ï¼ˆ600ç§’ï¼‰")
            return {"files_downloaded": 0, "total_size": 0}
        except FileNotFoundError:
            self.logger.error(f"âŒ æ‰¾ä¸åˆ°è„šæœ¬: {script}")
            self.logger.error(f"   å½“å‰ç›®å½•: {Path.cwd()}")
            self.logger.error(f"   è¯·ç¡®è®¤ {script} æ–‡ä»¶å­˜åœ¨")
            return {"files_downloaded": 0, "total_size": 0}
        except Exception as e:
            self.logger.error(f"âŒ Chrome æµè§ˆå™¨æ‰§è¡Œå¤±è´¥: {e}")
            import traceback
            self.logger.error(traceback.format_exc())
            return {"files_downloaded": 0, "total_size": 0}
    
    def _parse_ddg_output(self, stdout: str, stderr: str) -> Dict:
        """è§£æ ddg_fetcher çš„è¾“å‡º"""
        result = {
            "files_downloaded": 0,
            "total_size": 0,
            "urls_found": 0
        }
        
        # æŸ¥æ‰¾æ‘˜è¦è¡Œ
        for line in stdout.split('\n'):
            if "æˆåŠŸä¸‹è½½" in line or "ä¸‹è½½æˆåŠŸ" in line:
                import re
                match = re.search(r'(\d+)', line)
                if match:
                    result["files_downloaded"] = int(match.group(1))
            elif "MB" in line or "GB" in line:
                # å°è¯•æå–å¤§å°
                import re
                match = re.search(r'([\d.]+)\s*(MB|GB)', line)
                if match:
                    size = float(match.group(1))
                    unit = match.group(2)
                    result["total_size"] = int(size * (1024*1024 if unit == "MB" else 1024*1024*1024))
        
        # å¦‚æœæ²¡æœ‰è§£æåˆ°ï¼Œå°è¯•ç»Ÿè®¡æ–‡ä»¶
        if result["files_downloaded"] == 0:
            result["files_downloaded"] = self._count_new_files()
        
        return result
    
    def _count_downloaded_files(self) -> Dict:
        """ç»Ÿè®¡ä¸‹è½½çš„æ–‡ä»¶æ•°å’Œå¤§å°"""
        count = 0
        total_size = 0
        
        for vendor_dir in self.output_dir.iterdir():
            if vendor_dir.is_dir() and not vendor_dir.name.startswith(('_', '.')):
                for file in vendor_dir.rglob("*"):
                    if file.is_file() and file.suffix.lower() == '.pdf':
                        count += 1
                        total_size += file.stat().st_size
        
        return {
            "files_downloaded": count,
            "total_size": total_size
        }
    
    def _count_new_files(self) -> int:
        """ç»Ÿè®¡æ–°å¢æ–‡ä»¶æ•°ï¼ˆåŸºäºå®é™…æ–‡ä»¶ç³»ç»Ÿï¼‰"""
        # è¿”å›å½“å‰å®é™… PDF æ–‡ä»¶æ•°
        count = 0
        for vendor_dir in self.output_dir.iterdir():
            if vendor_dir.is_dir() and not vendor_dir.name.startswith(('_', '.')):
                for file in vendor_dir.rglob("*.pdf"):
                    if file.is_file():
                        count += 1
        return count
    
    def _check_limits(self) -> bool:
        """æ£€æŸ¥é™åˆ¶ï¼ˆåŸºäºå®é™…æ–‡ä»¶ç³»ç»Ÿç»Ÿè®¡ï¼‰"""
        # é‡æ–°ç»Ÿè®¡å®é™…æ–‡ä»¶æ•°å’Œå¤§å°
        actual_stats = self._count_downloaded_files()
        self.total_files_downloaded = actual_stats["files_downloaded"]
        self.total_size_downloaded = actual_stats["total_size"]
        
        size_limit = self.config["total_size_limit_gb"] * 1024 * 1024 * 1024
        
        if self.total_size_downloaded >= size_limit:
            self.logger.warning(f"âš ï¸  è¾¾åˆ°å¤§å°é™åˆ¶ ({self.total_size_downloaded / (1024**3):.2f} GB / {self.config['total_size_limit_gb']} GB)")
            return True
        
        if self.total_files_downloaded >= self.config["total_files_limit"]:
            self.logger.warning(f"âš ï¸  è¾¾åˆ°æ–‡ä»¶æ•°é™åˆ¶ ({self.total_files_downloaded} / {self.config['total_files_limit']})")
            return True
        
        return False
    
    def _print_round_summary(self, round_stats: Dict):
        """æ‰“å°æ€»ç»“"""
        self.logger.info(f"\n{'='*60}")
        self.logger.info(f"ğŸ“Š ç¬¬ {self.current_round + 1} è½®æ€»ç»“")
        self.logger.info(f"{'='*60}")
        self.logger.info(f"æœ¬è½®æ–‡ä»¶: {round_stats['files_downloaded']}")
        self.logger.info(f"æœ¬è½®å¤§å°: {round_stats['total_size'] / (1024*1024):.2f} MB")
        self.logger.info(f"ç´¯è®¡æ–‡ä»¶: {self.total_files_downloaded}")
        self.logger.info(f"ç´¯è®¡å¤§å°: {self.total_size_downloaded / (1024*1024*1024):.2f} GB")
        self.logger.info(f"{'='*60}\n")
    
    def run(self):
        """è¿è¡Œ"""
        self.logger.info("\n" + "ğŸš€ å¯åŠ¨æŒç»­æœç´¢ç³»ç»Ÿ".center(60, "="))
        self.logger.info(f"è¾“å‡º: {self.output_dir}")
        self.logger.info(f"ä½¿ç”¨: Chrome æµè§ˆå™¨ç‰ˆï¼ˆå¿…éœ€ï¼Œä»¥é¿å…è¯·æ±‚è¢«æ‹’ç»ï¼‰")
        self.logger.info("ğŸ’¡ æŒ‰ Ctrl+C å¯éšæ—¶å®‰å…¨é€€å‡º\n")
        
        try:
            if not self._initialize_components():
                return
        except KeyboardInterrupt:
            self.logger.warning("\nâš ï¸ åˆå§‹åŒ–è¢«ä¸­æ–­")
            return
        
        try:
            self.is_running = True
            
            while self.is_running:
                # æ£€æŸ¥é™åˆ¶
                if self.config["max_rounds"] > 0 and self.current_round >= self.config["max_rounds"]:
                    self.logger.info(f"âœ… è¾¾åˆ°æœ€å¤§è½®æ•°")
                    break
                
                if self._check_limits():
                    break
                
                # ç”Ÿæˆå…³é”®è¯
                try:
                    keywords = self._generate_keywords()
                    if not keywords:
                        self.logger.warning("âš ï¸  æ— æ–°å…³é”®è¯")
                        time.sleep(60)
                        continue
                except KeyboardInterrupt:
                    raise
                except Exception as e:
                    self.logger.error(f"âŒ ç”Ÿæˆå…³é”®è¯å¤±è´¥: {e}")
                    time.sleep(30)
                    continue
                
                # æœç´¢ä¸‹è½½
                try:
                    round_stats = self._search_and_download(keywords)
                    
                    # é‡æ–°ç»Ÿè®¡å®é™…æ–‡ä»¶æ•°ï¼ˆé¿å…é‡å¤è®¡æ•°ï¼‰
                    actual_stats = self._count_downloaded_files()
                    self.total_files_downloaded = actual_stats["files_downloaded"]
                    self.total_size_downloaded = actual_stats["total_size"]
                    
                    # æ‰“å°æ€»ç»“
                    self._print_round_summary(round_stats)
                except KeyboardInterrupt:
                    raise
                except Exception as e:
                    self.logger.error(f"âŒ æœç´¢ä¸‹è½½å‡ºé”™: {e}")
                
                # æ›´æ–°è½®æ•°
                self.current_round += 1
                
                # ä¿å­˜çŠ¶æ€
                if self.current_round % self.config["save_state_interval"] == 0:
                    self._save_state()
                
                # æ˜¾ç¤ºç»Ÿè®¡
                if self.current_round % 5 == 0:
                    self.keyword_manager.print_statistics()
                
                # ç­‰å¾…ï¼ˆåˆ†æ®µç¡çœ ä»¥ä¾¿å“åº”ä¸­æ–­ï¼‰
                if self.is_running:
                    interval = self.config["round_interval"]
                    self.logger.info(f"â¸ï¸  ç­‰å¾… {interval} ç§’...\n")
                    
                    # åˆ†æ®µç¡çœ ï¼Œæ¯ç§’æ£€æŸ¥ä¸€æ¬¡ä¸­æ–­
                    for _ in range(interval):
                        if not self.is_running:
                            break
                        time.sleep(1)
            
            # æœ€ç»ˆç»Ÿè®¡
            self.logger.info("\n" + "ğŸ‰ å®Œæˆ".center(60, "="))
            self.keyword_manager.print_statistics()
        
        except KeyboardInterrupt:
            self.logger.warning("\nâš ï¸ æ”¶åˆ°ä¸­æ–­ä¿¡å·ï¼Œæ­£åœ¨å®‰å…¨é€€å‡º...")
        except Exception as e:
            self.logger.error(f"âŒ é”™è¯¯: {e}", exc_info=True)
        finally:
            self.is_running = False
            self._save_state()
            self._cleanup()
            self.logger.info("âœ… ç¨‹åºå·²å®‰å…¨é€€å‡º")


def setup_logging(debug: bool = False) -> logging.Logger:
    """é…ç½®æ—¥å¿—"""
    level = logging.DEBUG if debug else logging.INFO
    logging.basicConfig(
        level=level,
        format="%(asctime)s [%(levelname)s] %(message)s",
        datefmt="%Y-%m-%d %H:%M:%S",
    )
    return logging.getLogger("integrated_searcher")


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description="æŒç»­æœç´¢ä¸‹è½½ç³»ç»Ÿ")
    parser.add_argument("-o", "--output", type=Path, default=Path("downloads_continuous"))
    parser.add_argument("-k", "--keywords-db", type=Path, default=Path("keywords.json"))
    parser.add_argument("-c", "--config", type=Path)
    parser.add_argument("--debug", action="store_true")
    parser.add_argument("--rounds", type=int, default=0)
    # æ³¨æ„ï¼šæœç´¢å’Œä¸‹è½½å¿…é¡»é€šè¿‡ Chrome æµè§ˆå™¨ï¼Œå¦åˆ™ä¼šè¢«æ‹’ç»
    
    args = parser.parse_args()
    logger = setup_logging(args.debug)
    
    # åŠ è½½é…ç½®
    config = None
    if args.config and args.config.exists():
        with open(args.config, 'r', encoding='utf-8-sig') as f:  # utf-8-sig è‡ªåŠ¨å¤„ç† BOM
            config = json.load(f)
    
    if config is None:
        config = {}
    
    if args.rounds > 0:
        config["max_rounds"] = args.rounds
    
    # è¿è¡Œï¼ˆå¼ºåˆ¶ä½¿ç”¨ Chrome æµè§ˆå™¨ï¼‰
    searcher = IntegratedSearcher(
        output_dir=args.output,
        keyword_db_path=args.keywords_db,
        use_browser=True,  # å¼ºåˆ¶ä½¿ç”¨ Chrome æµè§ˆå™¨
        config=config,
        logger=logger
    )
    
    searcher.run()


if __name__ == "__main__":
    main()
