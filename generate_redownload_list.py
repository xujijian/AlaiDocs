#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""ç”Ÿæˆé‡æ–°ä¸‹è½½æ¸…å•"""

import json
import sqlite3
from pathlib import Path
from collections import defaultdict

print("="*70)
print("ç”Ÿæˆä¸¢å¤±æ–‡ä»¶é‡æ–°ä¸‹è½½æ¸…å•")
print("="*70)

# 1. è·å–æ‰€æœ‰ä¸‹è½½è®°å½•
results_file = Path("downloads_continuous/results.jsonl")
downloaded_files = {}

if results_file.exists():
    with open(results_file, 'r', encoding='utf-8') as f:
        for line in f:
            record = json.loads(line)
            if record.get('status') == 'success':
                filename = record.get('filename')
                url = record.get('url')
                vendor = record.get('vendor')
                if filename:
                    downloaded_files[filename] = {
                        'url': url,
                        'vendor': vendor,
                        'record': record
                    }

print(f"âœ… æˆåŠŸä¸‹è½½è®°å½•: {len(downloaded_files)} ä¸ª")

# 2. è·å–çŸ¥è¯†åº“ä¸­çš„æ–‡ä»¶åˆ—è¡¨
kb_path = Path(r"D:\E-BOOK\axis-SQLite\kb.sqlite")
kb_files = set()
if kb_path.exists():
    conn = sqlite3.connect(str(kb_path))
    cursor = conn.cursor()
    cursor.execute('SELECT path FROM documents')
    for row in cursor.fetchall():
        filename = Path(row[0]).name
        kb_files.add(filename)
    conn.close()

print(f"ğŸ“š çŸ¥è¯†åº“è®°å½•: {len(kb_files)} ä¸ª")

# 3. æ£€æŸ¥å½“å‰å­˜åœ¨çš„æ–‡ä»¶
base_dir = Path(r"D:\E-BOOK\axis-dcdc-pdf")
downloads_dir = Path("downloads_continuous")

existing_files = set()
if base_dir.exists():
    for pdf in base_dir.rglob("*.pdf"):
        existing_files.add(pdf.name)
if downloads_dir.exists():
    for pdf in downloads_dir.rglob("*.pdf"):
        existing_files.add(pdf.name)

print(f"ğŸ“ å½“å‰å­˜åœ¨: {len(existing_files)} ä¸ª")

# 4. æ‰¾å‡ºä¸¢å¤±çš„æ–‡ä»¶
missing_in_kb = kb_files - existing_files
missing_downloaded = set(downloaded_files.keys()) - existing_files

print(f"\nâŒ çŸ¥è¯†åº“ä¸­ä¸¢å¤±: {len(missing_in_kb)} ä¸ª")
print(f"âŒ å·²ä¸‹è½½ä½†ä¸¢å¤±: {len(missing_downloaded)} ä¸ª")

# 5. ç”Ÿæˆé‡æ–°ä¸‹è½½æ¸…å•
redownload_list = []
for filename in missing_downloaded:
    if filename in downloaded_files:
        info = downloaded_files[filename]
        redownload_list.append({
            'filename': filename,
            'url': info['url'],
            'vendor': info['vendor']
        })

# æŒ‰å‚å•†åˆ†ç»„
by_vendor = defaultdict(list)
for item in redownload_list:
    by_vendor[item['vendor']].append(item)

# ä¿å­˜æ¸…å•
output_file = Path("redownload_list.json")
with open(output_file, 'w', encoding='utf-8') as f:
    json.dump(redownload_list, f, ensure_ascii=False, indent=2)

print(f"\nâœ… å·²ç”Ÿæˆé‡æ–°ä¸‹è½½æ¸…å•: {output_file}")
print(f"   æ€»è®¡éœ€é‡æ–°ä¸‹è½½: {len(redownload_list)} ä¸ªæ–‡ä»¶")

print("\næŒ‰å‚å•†ç»Ÿè®¡:")
for vendor, items in sorted(by_vendor.items(), key=lambda x: len(x[1]), reverse=True):
    print(f"  {vendor}: {len(items)}")

print("\n" + "="*70)
print("ä¸‹ä¸€æ­¥æ“ä½œå»ºè®®:")
print("="*70)
print("1. æŸ¥çœ‹ redownload_list.json ç¡®è®¤éœ€è¦é‡æ–°ä¸‹è½½çš„æ–‡ä»¶")
print("2. è¿è¡Œé‡æ–°ä¸‹è½½è„šæœ¬ï¼ˆéœ€è¦åˆ›å»ºï¼‰")
print("3. æˆ–è€…è®©ä¸‹è½½å™¨ç»§ç»­è¿è¡Œï¼Œè‡ªç„¶ä¼šé‡æ–°ä¸‹è½½è¿™äº›æ–‡ä»¶")
