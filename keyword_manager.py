#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å…³é”®è¯ç®¡ç†å™¨
ç®¡ç†å·²ä½¿ç”¨çš„å…³é”®è¯ï¼Œè¿½è¸ªæ•ˆæœï¼Œé¿å…é‡å¤

ä½œè€…: AI åŠ©æ‰‹
ç‰ˆæœ¬: 1.0.0
æ—¥æœŸ: 2026-01-26
Python: 3.10+
"""

import json
import logging
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Optional, Set


class KeywordManager:
    """å…³é”®è¯ç®¡ç†å™¨"""
    
    def __init__(self, db_path: Path, logger: Optional[logging.Logger] = None):
        """
        åˆå§‹åŒ–å…³é”®è¯ç®¡ç†å™¨
        
        Args:
            db_path: æ•°æ®åº“æ–‡ä»¶è·¯å¾„ï¼ˆJSONæ ¼å¼ï¼‰
            logger: æ—¥å¿—è®°å½•å™¨
        """
        self.db_path = Path(db_path)
        self.logger = logger or logging.getLogger(__name__)
        self.data = self._load_db()
    
    def _load_db(self) -> Dict:
        """åŠ è½½æ•°æ®åº“"""
        if self.db_path.exists():
            try:
                with open(self.db_path, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    self.logger.info(f"ğŸ“š åŠ è½½å…³é”®è¯æ•°æ®åº“: {len(data.get('keywords', {}))} ä¸ªå…³é”®è¯")
                    return data
            except Exception as e:
                self.logger.error(f"âŒ åŠ è½½æ•°æ®åº“å¤±è´¥: {e}")
        
        # åˆå§‹åŒ–ç©ºæ•°æ®åº“
        return {
            "keywords": {},  # å…³é”®è¯: {used_count, last_used, files_found, total_size}
            "statistics": {
                "total_keywords_used": 0,
                "total_searches": 0,
                "total_files_downloaded": 0,
                "last_updated": None
            }
        }
    
    def _save_db(self):
        """ä¿å­˜æ•°æ®åº“"""
        try:
            self.db_path.parent.mkdir(parents=True, exist_ok=True)
            with open(self.db_path, 'w', encoding='utf-8') as f:
                json.dump(self.data, f, indent=2, ensure_ascii=False)
            self.logger.debug(f"ğŸ’¾ ä¿å­˜å…³é”®è¯æ•°æ®åº“")
        except Exception as e:
            self.logger.error(f"âŒ ä¿å­˜æ•°æ®åº“å¤±è´¥: {e}")
    
    def add_keyword(self, keyword: str, files_found: int = 0, total_size: int = 0):
        """
        æ·»åŠ æˆ–æ›´æ–°å…³é”®è¯
        
        Args:
            keyword: å…³é”®è¯
            files_found: æ‰¾åˆ°çš„æ–‡ä»¶æ•°
            total_size: æ–‡ä»¶æ€»å¤§å°ï¼ˆå­—èŠ‚ï¼‰
        """
        keyword_lower = keyword.lower().strip()
        
        if keyword_lower in self.data["keywords"]:
            # æ›´æ–°ç°æœ‰å…³é”®è¯
            kw_data = self.data["keywords"][keyword_lower]
            kw_data["used_count"] += 1
            kw_data["files_found"] += files_found
            kw_data["total_size"] += total_size
            kw_data["last_used"] = datetime.now().isoformat()
        else:
            # æ·»åŠ æ–°å…³é”®è¯
            self.data["keywords"][keyword_lower] = {
                "original": keyword,
                "used_count": 1,
                "files_found": files_found,
                "total_size": total_size,
                "first_used": datetime.now().isoformat(),
                "last_used": datetime.now().isoformat()
            }
            self.data["statistics"]["total_keywords_used"] += 1
        
        self.data["statistics"]["total_searches"] += 1
        self.data["statistics"]["total_files_downloaded"] += files_found
        self.data["statistics"]["last_updated"] = datetime.now().isoformat()
        
        self._save_db()
    
    def is_keyword_used(self, keyword: str) -> bool:
        """æ£€æŸ¥å…³é”®è¯æ˜¯å¦å·²ä½¿ç”¨"""
        return keyword.lower().strip() in self.data["keywords"]
    
    def get_keyword_info(self, keyword: str) -> Optional[Dict]:
        """è·å–å…³é”®è¯ä¿¡æ¯"""
        return self.data["keywords"].get(keyword.lower().strip())
    
    def get_all_keywords(self) -> List[str]:
        """è·å–æ‰€æœ‰å·²ä½¿ç”¨çš„å…³é”®è¯"""
        return [kw_data["original"] for kw_data in self.data["keywords"].values()]
    
    def get_recent_keywords(self, limit: int = 20) -> List[str]:
        """è·å–æœ€è¿‘ä½¿ç”¨çš„å…³é”®è¯"""
        keywords = sorted(
            self.data["keywords"].items(),
            key=lambda x: x[1]["last_used"],
            reverse=True
        )
        return [kw_data["original"] for _, kw_data in keywords[:limit]]
    
    def get_effective_keywords(self, min_files: int = 1, limit: int = 20) -> List[Dict]:
        """
        è·å–æ•ˆæœæœ€å¥½çš„å…³é”®è¯
        
        Args:
            min_files: æœ€å°‘æ–‡ä»¶æ•°
            limit: è¿”å›æ•°é‡
            
        Returns:
            å…³é”®è¯åˆ—è¡¨ï¼ŒæŒ‰æ•ˆæœæ’åº
        """
        effective = [
            {
                "keyword": kw_data["original"],
                "files_found": kw_data["files_found"],
                "total_size": kw_data["total_size"],
                "used_count": kw_data["used_count"],
                "avg_files": kw_data["files_found"] / kw_data["used_count"]
            }
            for kw_data in self.data["keywords"].values()
            if kw_data["files_found"] >= min_files
        ]
        
        effective.sort(key=lambda x: x["avg_files"], reverse=True)
        return effective[:limit]
    
    def get_ineffective_keywords(self, max_files: int = 0, limit: int = 20) -> List[str]:
        """è·å–æ•ˆæœä¸å¥½çš„å…³é”®è¯"""
        ineffective = [
            kw_data["original"]
            for kw_data in self.data["keywords"].values()
            if kw_data["files_found"] <= max_files
        ]
        return ineffective[:limit]
    
    def filter_new_keywords(self, keywords: List[str], allow_reuse_days: int = 7) -> List[str]:
        """
        è¿‡æ»¤å‡ºå¯ç”¨çš„å…³é”®è¯
        
        Args:
            keywords: å¾…è¿‡æ»¤çš„å…³é”®è¯åˆ—è¡¨
            allow_reuse_days: å…è®¸é‡ç”¨çš„å¤©æ•°é—´éš”ï¼ˆé»˜è®¤7å¤©ï¼‰
            
        Returns:
            å¯ç”¨å…³é”®è¯åˆ—è¡¨ï¼ˆæœªä½¿ç”¨çš„ + è¶…è¿‡é‡ç”¨é—´éš”çš„ï¼‰
        """
        from datetime import datetime, timedelta
        
        reuse_keywords = []
        new_keywords = []
        cutoff_time = (datetime.now() - timedelta(days=allow_reuse_days)).isoformat()
        
        for kw in keywords:
            if not self.is_keyword_used(kw):
                # å…¨æ–°å…³é”®è¯
                new_keywords.append(kw)
            else:
                # å·²ç”¨å…³é”®è¯ï¼Œæ£€æŸ¥æ˜¯å¦å¯é‡ç”¨
                kw_info = self.get_keyword_info(kw)
                if kw_info:
                    # å¦‚æœè¶…è¿‡é‡ç”¨é—´éš” ä¸” ä¹‹å‰æœ‰æ•ˆæœï¼ˆfiles_found > 0ï¼‰
                    if kw_info["last_used"] < cutoff_time and kw_info["files_found"] > 0:
                        reuse_keywords.append(kw)
        
        # ä¼˜å…ˆä½¿ç”¨æ–°å…³é”®è¯ï¼Œä¸è¶³æ—¶è¡¥å……å¯é‡ç”¨çš„
        result = new_keywords + reuse_keywords
        
        if reuse_keywords:
            self.logger.info(f"ğŸ”„ é‡ç”¨ {len(reuse_keywords)} ä¸ªæ—§å…³é”®è¯ï¼ˆè¶…è¿‡ {allow_reuse_days} å¤©ä¸”æ›¾æœ‰æ•ˆï¼‰")
        
        return result
    
    def get_statistics(self) -> Dict:
        """è·å–ç»Ÿè®¡ä¿¡æ¯"""
        stats = self.data["statistics"].copy()
        
        if self.data["keywords"]:
            total_files = sum(kw["files_found"] for kw in self.data["keywords"].values())
            total_searches = stats["total_searches"]
            stats["avg_files_per_search"] = total_files / total_searches if total_searches > 0 else 0
            
            total_size = sum(kw["total_size"] for kw in self.data["keywords"].values())
            stats["total_size_mb"] = total_size / (1024 * 1024)
        
        return stats
    
    def print_statistics(self):
        """æ‰“å°ç»Ÿè®¡ä¿¡æ¯"""
        stats = self.get_statistics()
        
        self.logger.info("\n" + "="*60)
        self.logger.info("ğŸ“Š å…³é”®è¯ä½¿ç”¨ç»Ÿè®¡")
        self.logger.info("="*60)
        self.logger.info(f"æ€»å…³é”®è¯æ•°: {stats['total_keywords_used']}")
        self.logger.info(f"æ€»æœç´¢æ¬¡æ•°: {stats['total_searches']}")
        self.logger.info(f"æ€»ä¸‹è½½æ–‡ä»¶æ•°: {stats['total_files_downloaded']}")
        self.logger.info(f"å¹³å‡æ¯æ¬¡æœç´¢æ–‡ä»¶æ•°: {stats.get('avg_files_per_search', 0):.2f}")
        self.logger.info(f"æ€»ä¸‹è½½å¤§å°: {stats.get('total_size_mb', 0):.2f} MB")
        
        if stats['last_updated']:
            self.logger.info(f"æœ€åæ›´æ–°: {stats['last_updated']}")
        
        self.logger.info("="*60 + "\n")
        
        # æ˜¾ç¤ºæ•ˆæœæœ€å¥½çš„å…³é”®è¯
        effective = self.get_effective_keywords(min_files=1, limit=10)
        if effective:
            self.logger.info("ğŸ† æ•ˆæœæœ€å¥½çš„å…³é”®è¯ (Top 10):")
            for i, kw_info in enumerate(effective, 1):
                self.logger.info(
                    f"{i:2d}. {kw_info['keyword']}: "
                    f"{kw_info['files_found']} æ–‡ä»¶ "
                    f"(å¹³å‡ {kw_info['avg_files']:.1f} æ–‡ä»¶/æ¬¡)"
                )
            self.logger.info("")
        
        # æ˜¾ç¤ºæœ€è¿‘ä½¿ç”¨çš„å…³é”®è¯
        recent = self.get_recent_keywords(limit=10)
        if recent:
            self.logger.info("ğŸ• æœ€è¿‘ä½¿ç”¨çš„å…³é”®è¯ (Top 10):")
            for i, kw in enumerate(recent, 1):
                info = self.get_keyword_info(kw)
                self.logger.info(
                    f"{i:2d}. {kw}: "
                    f"{info['files_found']} æ–‡ä»¶, "
                    f"ä½¿ç”¨ {info['used_count']} æ¬¡"
                )
            self.logger.info("")


def main():
    """æµ‹è¯•å‡½æ•°"""
    logging.basicConfig(
        level=logging.INFO,
        format="%(asctime)s [%(levelname)s] %(message)s",
    )
    
    logger = logging.getLogger(__name__)
    
    # æµ‹è¯•å…³é”®è¯ç®¡ç†å™¨
    db_path = Path("test_keywords.json")
    manager = KeywordManager(db_path, logger)
    
    # æ·»åŠ ä¸€äº›æµ‹è¯•å…³é”®è¯
    test_keywords = [
        ("LM5164 datasheet", 5, 10000000),
        ("buck converter design", 3, 5000000),
        ("synchronous DCDC", 8, 15000000),
        ("automotive power supply", 2, 3000000),
        ("high efficiency converter", 0, 0),
    ]
    
    for kw, files, size in test_keywords:
        manager.add_keyword(kw, files, size)
        logger.info(f"æ·»åŠ å…³é”®è¯: {kw}")
    
    # æ‰“å°ç»Ÿè®¡
    manager.print_statistics()
    
    # æµ‹è¯•è¿‡æ»¤
    new_keywords = [
        "LM5164 datasheet",  # å·²å­˜åœ¨
        "boost converter design",  # æ–°å…³é”®è¯
        "flyback transformer",  # æ–°å…³é”®è¯
    ]
    
    filtered = manager.filter_new_keywords(new_keywords)
    logger.info(f"è¿‡æ»¤åçš„æ–°å…³é”®è¯: {filtered}")


if __name__ == "__main__":
    main()
