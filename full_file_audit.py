#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""å®Œæ•´ç»Ÿè®¡æ‰€æœ‰æ–‡ä»¶å»å‘"""

import sqlite3
import json
from pathlib import Path
from collections import Counter

print("="*70)
print("å®Œæ•´æ–‡ä»¶è¿½è¸ªæŠ¥å‘Š")
print("="*70)

# 1. ä¸‹è½½è®°å½•
results_file = Path("downloads_continuous/results.jsonl")
if results_file.exists():
    with open(results_file, 'r', encoding='utf-8') as f:
        download_records = [json.loads(line) for line in f]
    print(f"\nğŸ“¥ ä¸‹è½½è®°å½•æ€»æ•°: {len(download_records)}")
    
    # ç»Ÿè®¡æˆåŠŸ/å¤±è´¥
    success = sum(1 for r in download_records if r.get('status') == 'success')
    failed = len(download_records) - success
    print(f"  âœ… æˆåŠŸ: {success}")
    print(f"  âŒ å¤±è´¥: {failed}")

# 2. åˆ†ç±»æ•°æ®åº“
classify_db = Path("classified_files.db")
if classify_db.exists():
    conn = sqlite3.connect(str(classify_db))
    cursor = conn.cursor()
    cursor.execute('SELECT COUNT(*) FROM processed_files')
    classified_count = cursor.fetchone()[0]
    print(f"\nğŸ—‚ï¸  åˆ†ç±»å™¨å¤„ç†æ•°: {classified_count}")
    
    # æ£€æŸ¥å­˜åœ¨æƒ…å†µ
    cursor.execute('SELECT dst_path FROM processed_files')
    classified_paths = [row[0] for row in cursor.fetchall()]
    existing_classified = sum(1 for p in classified_paths if p and Path(p).exists())
    print(f"  âœ… å®é™…å­˜åœ¨: {existing_classified}")
    print(f"  âŒ å·²æ¶ˆå¤±: {classified_count - existing_classified}")
    conn.close()

# 3. çŸ¥è¯†åº“
kb_path = Path(r"D:\E-BOOK\axis-SQLite\kb.sqlite")
if kb_path.exists():
    conn = sqlite3.connect(str(kb_path))
    cursor = conn.cursor()
    cursor.execute('SELECT COUNT(DISTINCT doc_id) FROM documents')
    kb_doc_count = cursor.fetchone()[0]
    print(f"\nğŸ“š çŸ¥è¯†åº“æ–‡æ¡£æ•°: {kb_doc_count}")
    
    base_dir = Path(r"D:\E-BOOK\axis-dcdc-pdf")
    cursor.execute('SELECT path FROM documents')
    kb_paths = [row[0] for row in cursor.fetchall()]
    existing_kb = sum(1 for p in kb_paths if (base_dir / p).exists())
    print(f"  âœ… å®é™…å­˜åœ¨: {existing_kb}")
    print(f"  âŒ å·²æ¶ˆå¤±: {kb_doc_count - existing_kb}")
    conn.close()

# 4. å½“å‰æ–‡ä»¶ç³»ç»Ÿ
downloads_dir = Path("downloads_continuous")
axis_dcdc_dir = Path(r"D:\E-BOOK\axis-dcdc-pdf")

downloads_count = len(list(downloads_dir.rglob("*.pdf"))) if downloads_dir.exists() else 0
axis_dcdc_count = len(list(axis_dcdc_dir.rglob("*.pdf"))) if axis_dcdc_dir.exists() else 0

print(f"\nğŸ“ å½“å‰æ–‡ä»¶ç³»ç»Ÿ:")
print(f"  downloads_continuous: {downloads_count}")
print(f"  axis-dcdc-pdf: {axis_dcdc_count}")
print(f"  æ€»è®¡: {downloads_count + axis_dcdc_count}")

print("\n" + "="*70)
print("æ–‡ä»¶æµå‘åˆ†æ:")
print("="*70)
if results_file.exists() and classify_db.exists():
    downloaded_success = success
    print(f"1. æˆåŠŸä¸‹è½½: {downloaded_success}")
    print(f"2. åˆ†ç±»å¤„ç†: {classified_count}")
    print(f"3. è¿›å…¥çŸ¥è¯†åº“: {kb_doc_count}")
    print(f"4. ç°å­˜æ–‡ä»¶: {downloads_count + axis_dcdc_count}")
    print(f"\nâš ï¸  ä¸¢å¤±æ–‡ä»¶: {downloaded_success - (downloads_count + axis_dcdc_count)}")
